{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Rregression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0HqgvPSKzALy2r06rp+2F"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "apoiVW1QuWmV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Logistic_regression:\n",
        "\n",
        "    def __init__(self, X, Y):\n",
        "        self.X, self.Y, self.beta = X, Y, np.zeros((X.shape[1], 1)).flatten()\n",
        "\n",
        "    def log_loss(self):\n",
        "        return np.dot(self.Y.T, np.log(self.sigmoid(self.X))) + np.dot((1 - self.Y).T, np.log(1 - self.sigmoid(self.X)))\n",
        "\n",
        "    def cost_function(self):\n",
        "        return -np.sum(self.log_loss()) + self.epsilon * np.sum(self.update_weights() ** 2)\n",
        "\n",
        "    def update_weights(self):\n",
        "        dev_grad = np.dot(self.X.T, (self.predict(self.X) - self.Y)) / self.Y.shape[0]\n",
        "        self.beta = self.beta - self.step_size * (dev_grad - (self.epsilon * self.beta) / self.Y.shape[0])\n",
        "        return self.beta\n",
        "\n",
        "    def fit(self, max_steps=5000, step_size=0.000000404, epsilon=0.00000001):\n",
        "        self.bias = 0\n",
        "        self.step_size = step_size\n",
        "        self.epsilon = epsilon\n",
        "        for i in range(max_steps):\n",
        "            self.beta = self.update_weights()\n",
        "            self.bias = self.bias - step_size * (self.sigmoid(self.X) - self.Y).sum() / self.Y.shape[0]\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.h = self.sigmoid(X)\n",
        "        predict = np.where(self.h >= 0.5, 1, 0)\n",
        "        return predict\n",
        "\n",
        "    def sigmoid(self, X):\n",
        "        return 1 / (1 + np.exp(-np.dot(X, self.beta) + self.bias))\n"
      ],
      "metadata": {
        "id": "jx5HkcBPulGv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default = pd.read_csv('classification.csv')\n",
        "default.ed = default.ed.astype('category').cat.codes"
      ],
      "metadata": {
        "id": "DJnPg0cmuvXA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = default[default.columns.difference(['default'])], default.default\n",
        "X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)"
      ],
      "metadata": {
        "id": "TviZTh2Iuzrn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n"
      ],
      "metadata": {
        "id": "fkVA0XWvu1en"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = Logistic_regression(X_train, y_train)\n",
        "log_reg.fit(max_steps=10000, step_size=0.0001, epsilon=1e-14)\n",
        "train_pred = log_reg.predict(X_train)"
      ],
      "metadata": {
        "id": "hJQtULnou4jx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix from our implementation\n",
        "cm = confusion_matrix(train_pred, y_train)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6lDNZBxu7aS",
        "outputId": "d00d3bfa-2d27-436f-b50c-b0bfc5ba6c26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[330,  64],\n",
              "       [ 86,  80]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix from sklearn Logistic Regression model\n",
        "classifier = LogisticRegression(random_state=0, max_iter=10000, solver='lbfgs', multi_class='auto')\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_train)\n",
        "cm_1 = confusion_matrix(y_pred, y_train)\n",
        "cm_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGBPv9wku_9q",
        "outputId": "cdbf1045-9458-47bd-b92d-5e5319bed5b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[383,  70],\n",
              "       [ 33,  74]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jhL-Up0qvRIU"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}